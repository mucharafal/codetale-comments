[
  {
    "id" : "8f1af15a-8268-41fb-b1ae-997a521d9611",
    "prId" : 5315,
    "prUrl" : "https://github.com/digital-asset/daml/pull/5315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ea9e83b-8465-4701-b245-ab2d1580abb7",
        "parentId" : null,
        "authorId" : "8690c022-0eb5-4c0b-9f54-a9e6ad005a86",
        "body" : "Correct the wrapping of this line as well, please.",
        "createdAt" : "2020-04-01T15:22:19Z",
        "updatedAt" : "2020-04-01T15:23:05Z",
        "lastEditedBy" : "8690c022-0eb5-4c0b-9f54-a9e6ad005a86",
        "tags" : [
        ]
      }
    ],
    "commit" : "2beee020cac3ccd86a87358e05512687af93e7d4",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +435,439 @@  ): Future[LedgerId] = {\n    // Note that here we only store the ledger entry and we do not update anything else, such as the\n    // headRef. This is OK since this initialization\n    // step happens before we start up the sql ledger at all, so it's running in isolation.\n"
  },
  {
    "id" : "c3648643-6419-41f8-8ec3-3d4cff59cb9a",
    "prId" : 5100,
    "prUrl" : "https://github.com/digital-asset/daml/pull/5100",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "157286a4-f1dc-4687-9a13-2b74f322046d",
        "parentId" : null,
        "authorId" : "8690c022-0eb5-4c0b-9f54-a9e6ad005a86",
        "body" : "cannot",
        "createdAt" : "2020-03-25T11:26:40Z",
        "updatedAt" : "2020-03-25T11:28:29Z",
        "lastEditedBy" : "8690c022-0eb5-4c0b-9f54-a9e6ad005a86",
        "tags" : [
        ]
      }
    ],
    "commit" : "d421ae1a437d89063df1c3e40078f52885762eaf",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +184,188 @@      .get()\n      .fold[Either[String, Unit]](\n        Left(\"No ledger configuration available, can not validate ledger time\")\n      )(\n        config => config.timeModel.checkTime(ledgerTime, recordTime)"
  },
  {
    "id" : "de5c9fca-73b0-44ae-95b2-185f11d649a3",
    "prId" : 2131,
    "prUrl" : "https://github.com/digital-asset/daml/pull/2131",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69cfa389-59c6-4f8a-837c-9f96d812c93f",
        "parentId" : null,
        "authorId" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "body" : "This makes the code less resistant against adding a new case to `PersistenceResponse` (e.g., `PersistenceResponse.Error`). I don't have a strong opinion, but my personal preference would be listing both cases explicitly.",
        "createdAt" : "2019-07-16T14:09:30Z",
        "updatedAt" : "2019-07-29T11:11:32Z",
        "lastEditedBy" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "tags" : [
        ]
      },
      {
        "id" : "191ca30c-417f-4c12-a543-a794977fd7a3",
        "parentId" : "69cfa389-59c6-4f8a-837c-9f96d812c93f",
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "It's not clear to me why we should change the api of `LedgerDao` to return a `Map`, but then immediately discard the value with `_`. ",
        "createdAt" : "2019-07-17T07:21:55Z",
        "updatedAt" : "2019-07-29T11:11:32Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      },
      {
        "id" : "c036f097-618f-403f-86f7-33d641f2e2bc",
        "parentId" : "69cfa389-59c6-4f8a-837c-9f96d812c93f",
        "authorId" : "1a7c6bd0-63e1-4deb-9695-6d6e9742f90b",
        "body" : "It's not strictly necessary right now, but since it's information that it's available to the data access object I see no reason to discard it upstream either. Furthermore, it would be very difficult to understand in which case to return `Ok` and in which return `Duplicate` if the end result is mixed. Do you think we should add the concept of `Duplicate` to this layer as well?",
        "createdAt" : "2019-07-26T15:06:19Z",
        "updatedAt" : "2019-07-29T11:11:32Z",
        "lastEditedBy" : "1a7c6bd0-63e1-4deb-9695-6d6e9742f90b",
        "tags" : [
        ]
      }
    ],
    "commit" : "32b9c53286fc57cb866c7a586b41bb9fdf2064f6",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +360,364 @@        // discard the information; package upload is idempotent, apart from the fact\n        // that we only keep the knownSince and sourceDescription of the first upload.\n        UploadPackagesResult.Ok\n      }(DEC)\n  }"
  },
  {
    "id" : "057df128-7fb7-4d74-a766-329c86391138",
    "prId" : 1818,
    "prUrl" : "https://github.com/digital-asset/daml/pull/1818",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c92fd70-c362-4259-8bfe-1089a0e8a35b",
        "parentId" : null,
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "Not sure I understand. Why do we use `InMemoryPackageStore` for the SqlLedger?",
        "createdAt" : "2019-06-24T07:52:21Z",
        "updatedAt" : "2019-07-02T12:24:58Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      },
      {
        "id" : "b48b5f6f-4f20-4321-bbfb-dfbe8ea11eba",
        "parentId" : "8c92fd70-c362-4259-8bfe-1089a0e8a35b",
        "authorId" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "body" : "This PR is just WIP so far. First part was to move ownership of the package store to the `Ledger` instance. Next part will be copying the given `InMemoryPackageStore` (populated by the CLI arguments and scenario loader) to the PostgreSQL database on startup, and then serving package management calls from the database.",
        "createdAt" : "2019-06-24T14:27:31Z",
        "updatedAt" : "2019-07-02T12:24:58Z",
        "lastEditedBy" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "tags" : [
        ]
      },
      {
        "id" : "defa0949-9c35-4239-819d-04208fa79024",
        "parentId" : "8c92fd70-c362-4259-8bfe-1089a0e8a35b",
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "Alright, I'll shut up now and wait for your signal :)",
        "createdAt" : "2019-06-24T14:28:14Z",
        "updatedAt" : "2019-07-02T12:24:58Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      }
    ],
    "commit" : "bae23a0a96200d0ece436a646cceb68a50511f37",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +77,81 @@      timeProvider: TimeProvider,\n      acs: InMemoryActiveContracts,\n      packages: InMemoryPackageStore,\n      initialLedgerEntries: ImmArray[LedgerEntryWithLedgerEndIncrement],\n      queueDepth: Int,"
  },
  {
    "id" : "5ac7e5e6-0f06-458c-8f45-ae1ed2c0bccc",
    "prId" : 1818,
    "prUrl" : "https://github.com/digital-asset/daml/pull/1818",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf04573c-c02c-43b7-ae06-79eaf1bca115",
        "parentId" : null,
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "I'd rather we don't thread the `InMemoryPackageStore` all the way to the Ledger initialization, but rather we simply initialize the ledger and automatically upload the packages from \"the outside\" via the regular mechanism. What do you think? Duplicate packages will be \"ignored\" and the other packages just uploaded.",
        "createdAt" : "2019-06-28T08:33:09Z",
        "updatedAt" : "2019-07-02T12:24:58Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      },
      {
        "id" : "92b84990-29d8-47b1-a013-3d2f6f3f14ba",
        "parentId" : "bf04573c-c02c-43b7-ae06-79eaf1bca115",
        "authorId" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "body" : "Not sure about that. This `initialize` method also inserts the provided ACS and ledger entries (generated by the scenario loader) into the database, and conceptually the packages should be added before the ledger entries.\r\n\r\nIn practice, nothing would happen if we first copied the given ledger entries and ACS upon initialization, and then uploaded the packages later from the outside.",
        "createdAt" : "2019-06-28T09:08:50Z",
        "updatedAt" : "2019-07-02T12:24:58Z",
        "lastEditedBy" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "tags" : [
        ]
      },
      {
        "id" : "7857824e-deac-4c78-88f4-8d539bdf0adf",
        "parentId" : "bf04573c-c02c-43b7-ae06-79eaf1bca115",
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "I see. Looking at my postgres-index(er) branch, I see that it won't be a problem. ðŸ‘ ",
        "createdAt" : "2019-06-28T09:17:07Z",
        "updatedAt" : "2019-07-02T12:24:58Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      }
    ],
    "commit" : "bae23a0a96200d0ece436a646cceb68a50511f37",
    "line" : 178,
    "diffHunk" : "@@ -1,1 +436,440 @@                  s\"Initial ledger entries provided, presumably from scenario, but I'm picking up from an existing database, and thus they will not be used\")\n              }\n              if (packages.listLfPackagesSync().nonEmpty) {\n                logger.warn(\n                  s\"Initial packages provided, presumably as command line arguments, but I'm picking up from an existing database, and thus they will not be used\")"
  },
  {
    "id" : "53019eca-8d5d-4625-a914-12c400ddacd3",
    "prId" : 1505,
    "prUrl" : "https://github.com/digital-asset/daml/pull/1505",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a39cc06-7bc2-49c0-9384-f7d0453ca4b3",
        "parentId" : null,
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "That's merely ignoring the error, right? Which means that we actually lose the ledger entry. We probably should rather retry n times and then crash the application?",
        "createdAt" : "2019-06-04T07:58:15Z",
        "updatedAt" : "2019-06-04T09:19:19Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      },
      {
        "id" : "9a4f9bde-68f6-4d05-a052-0fe6a1587f84",
        "parentId" : "9a39cc06-7bc2-49c0-9384-f7d0453ca4b3",
        "authorId" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "body" : "I am not sure. Why can't the command just fail, and we put the retry responsibility on the client? I tend to shy away from ad-hoc retry logics, because you have to make arbitrary decisions which you might not be entitled to. In this case the commands in-flight have time related constraints for instance, so how long should we retry them?",
        "createdAt" : "2019-06-04T08:15:11Z",
        "updatedAt" : "2019-06-04T09:19:19Z",
        "lastEditedBy" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "tags" : [
        ]
      },
      {
        "id" : "bb0c6c34-2a4f-413a-a35f-e53d82b49316",
        "parentId" : "9a39cc06-7bc2-49c0-9384-f7d0453ca4b3",
        "authorId" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "body" : "Another thing is that a Postgres database can be down for a long time. A robust application should survive that and recover when it comes back. ",
        "createdAt" : "2019-06-04T08:16:23Z",
        "updatedAt" : "2019-06-04T09:19:19Z",
        "lastEditedBy" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "tags" : [
        ]
      },
      {
        "id" : "b5f3f314-a004-4fa2-9766-90664c2b1dbb",
        "parentId" : "9a39cc06-7bc2-49c0-9384-f7d0453ca4b3",
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "Is the command/transaction actually rejected? This would then trigger another write to the database that would fail, right?",
        "createdAt" : "2019-06-04T09:09:30Z",
        "updatedAt" : "2019-06-04T09:19:19Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      },
      {
        "id" : "26e3cbc1-4a27-4c3d-af9e-92930777b09a",
        "parentId" : "9a39cc06-7bc2-49c0-9384-f7d0453ca4b3",
        "authorId" : "eb431011-3221-41ae-bf30-e72dde278004",
        "body" : "Discussed offline: the postgres transaction will fail and thus be rolled back by `HikariJdbcConnectionProvider`. Since the client will never get a completion or a transaction, it should run into a command timeout and retry the command.",
        "createdAt" : "2019-06-04T09:31:48Z",
        "updatedAt" : "2019-06-04T09:31:49Z",
        "lastEditedBy" : "eb431011-3221-41ae-bf30-e72dde278004",
        "tags" : [
        ]
      }
    ],
    "commit" : "13bdebb80c5a71ce211dbac7c888c01f2468a665",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +186,190 @@                    //recovering from the failure so the persistence stream doesn't die\n                    logger.error(s\"Failed to persist entry with offset: $offset\", t)\n                    ()\n                }\n          })"
  },
  {
    "id" : "3e193bda-4654-485f-9a3e-dc9d5856798c",
    "prId" : 990,
    "prUrl" : "https://github.com/digital-asset/daml/pull/990",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "140c1902-382b-4d8e-ae42-0390bfe9469a",
        "parentId" : null,
        "authorId" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "body" : "it's not your fault, but I just noticed that we have a race in the persistence pipeline. As the entries can be persisted concurrently, they might get saved with non strictly increasing record times. The question is: When `offsetT2 > offsetT1 ` is/must `recordTimeT2 >= recordTimeT1` implied from it?",
        "createdAt" : "2019-05-08T09:21:48Z",
        "updatedAt" : "2019-05-09T08:23:50Z",
        "lastEditedBy" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "tags" : [
        ]
      },
      {
        "id" : "7cf9a6c8-22c8-43c7-baeb-6a1ac28d59ce",
        "parentId" : "140c1902-382b-4d8e-ae42-0390bfe9469a",
        "authorId" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "body" : "I take it back. I forgot that it's actually called via a callback, where the order is guaranteed. ",
        "createdAt" : "2019-05-08T10:58:23Z",
        "updatedAt" : "2019-05-09T08:23:50Z",
        "lastEditedBy" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "tags" : [
        ]
      }
    ],
    "commit" : "09bbdf689d930ffefebf0ef91ebc9a3d81880874",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +257,261 @@          tx.workflowId,\n          tx.ledgerEffectiveTime,\n          recordTime,\n          mappedTx,\n          mappedDisclosure"
  },
  {
    "id" : "8b6d89f1-ab0a-452e-80da-24fc3b339d6c",
    "prId" : 959,
    "prUrl" : "https://github.com/digital-asset/daml/pull/959",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac374207-55ec-49aa-916e-e2702eda898b",
        "parentId" : null,
        "authorId" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "body" : "@francesco-da This part was written while resolving a rebase conflict. It assigns an absolute ledger offset to each ledger entry produced by the scenario loader, and gives that whole list to the DAO to persist (along with the list of active contracts produced by the scenario loader).\r\n\r\nWhile writing this, I realize that because we are using the contracts produced by the scenario loader, the SQL backend will not persist contracts that have been created *and* archived within a scenario, so it will not be able to produce a valid ledger snapshot before the end of the scenario. I don't think this is an issue, just worth mentioning.",
        "createdAt" : "2019-05-15T14:13:22Z",
        "updatedAt" : "2019-05-15T16:27:45Z",
        "lastEditedBy" : "c83a17a2-0c0d-4811-9fe5-e560bb3ad87a",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4dc5b75fb95575adb8e21bb2ae04bcccdc97acf",
    "line" : 249,
    "diffHunk" : "@@ -1,1 +394,398 @@                  entriesWithOffset._2,\n                  entriesWithOffset._1)\n              } yield { initialId }\n\n          }(DEC)"
  },
  {
    "id" : "38adf4b1-37be-43b2-94a7-b8530a17180b",
    "prId" : 752,
    "prUrl" : "https://github.com/digital-asset/daml/pull/752",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "df3b1c80-b6f8-44a6-910e-cac2b0e7ecd7",
        "parentId" : null,
        "authorId" : "8e6a9b81-aba7-4206-84ba-06825f79e954",
        "body" : "```suggestion\r\n    // We process the requests in batches when under pressure (see semantics of `batch`). Note\r\n    // that this is safe on the read end because the readers rely on the dispatchers to know the\r\n    // ledger end, and not the database itself. This means that they will not start reading from the new\r\n    // ledger end until we tell them so, which we do when _all_ the entries have been committed.\r\n    mergedSources\r\n```",
        "createdAt" : "2019-04-29T16:10:26Z",
        "updatedAt" : "2019-04-29T16:12:32Z",
        "lastEditedBy" : "8e6a9b81-aba7-4206-84ba-06825f79e954",
        "tags" : [
        ]
      }
    ],
    "commit" : "274ca7de6c735c916257d57e61908ae8f5777ca0",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +139,143 @@    // ledger end, and not the database itself. This means that they will not start reading from the new\n    // ledger end until we tell them so, which we do when _all_ the entries have been committed.\n    mergedSources\n      .batch(noOfShortLivedConnections * 2L, e => Queue(e))((batch, e) => batch :+ e)\n      .mapAsync(1) { queue =>"
  },
  {
    "id" : "32d1f570-623f-4112-80f8-4cc294d6a044",
    "prId" : 611,
    "prUrl" : "https://github.com/digital-asset/daml/pull/611",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b6850b6-3066-4649-a2ba-3665991cbc8a",
        "parentId" : null,
        "authorId" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "body" : "doesn't make a difference in performance according to my local tests",
        "createdAt" : "2019-04-23T07:17:16Z",
        "updatedAt" : "2019-04-24T10:54:57Z",
        "lastEditedBy" : "e316b0c3-3da9-495c-b0fe-7fb96d032e37",
        "tags" : [
        ]
      }
    ],
    "commit" : "80a155bf0253163f8e06e1fb42f82f22e3ae95fe",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +63,67 @@    implicit val ec: ExecutionContext = DirectExecutionContext\n\n    val noOfShortLivedConnections = 8\n    val noOfStreamingConnections = 4\n"
  }
]